"""
Data Loader - Quantum Trader Pro
Chargement et gestion des donn√©es de march√© historiques et en temps r√©el
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from utils.logger import setup_logger
import time

class DataLoader:
    """
    Gestionnaire de donn√©es avec:
    - Chargement donn√©es historiques
    - Cache intelligent
    - Validation donn√©es
    - Resampling multi-timeframe
    - Mise √† jour temps r√©el
    """
    
    def __init__(self, client, config: Dict):
        """
        Initialise le data loader
        
        Args:
            client: Instance BinanceClient
            config: Configuration compl√®te du bot
        """
        self.client = client
        self.config = config
        self.logger = setup_logger('DataLoader')
        
        # Configuration
        self.symbol = config['symbols']['primary']
        timeframes_config = config.get('timeframes', {})
        self.trend_tf = timeframes_config.get('trend', '1h')
        self.signal_tf = timeframes_config.get('signal', '5m')
        self.micro_tf = timeframes_config.get('micro', '1m')
        
        lookback = timeframes_config.get('lookback', {})
        self.lookback_short = lookback.get('short', 100)
        self.lookback_medium = lookback.get('medium', 500)
        self.lookback_long = lookback.get('long', 1000)
        
        # Cache
        self.cache = {}
        self.cache_enabled = config.get('performance', {}).get('cache_indicators', True)
        self.cache_ttl = config.get('performance', {}).get('cache_ttl_seconds', 300)
        self.cache_timestamps = {}
        
        # √âtat
        self.last_update = {}
        
        self.logger.info("‚úÖ Data Loader initialis√©")
    
    def load_historical_data(
        self,
        symbol: Optional[str] = None,
        timeframe: str = '1h',
        limit: int = 1000,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> pd.DataFrame:
        """
        Charge les donn√©es historiques
        
        Args:
            symbol: Paire de trading (d√©faut: config)
            timeframe: Timeframe (1m, 5m, 1h, etc.)
            limit: Nombre de bougies
            start_date: Date de d√©but (format: YYYY-MM-DD)
            end_date: Date de fin
        
        Returns:
            DataFrame avec colonnes: timestamp, open, high, low, close, volume
        """
        
        symbol = symbol or self.symbol
        
        self.logger.info(
            f"üì• Chargement donn√©es: {symbol} {timeframe} (limit: {limit})"
        )
        
        try:
            # V√©rifier cache
            cache_key = f"{symbol}_{timeframe}_{limit}"
            if self._is_cache_valid(cache_key):
                self.logger.debug(f"‚úÖ Donn√©es r√©cup√©r√©es du cache: {cache_key}")
                return self.cache[cache_key].copy()
            
            # Charger depuis exchange
            ohlcv = self.client.fetch_ohlcv(
                timeframe=timeframe,
                limit=limit,
                since=self._parse_date(start_date) if start_date else None
            )
            
            if ohlcv is None or len(ohlcv) == 0:
                self.logger.error(f"‚ùå Aucune donn√©e re√ßue pour {symbol} {timeframe}")
                return pd.DataFrame()
            
            # Convertir en DataFrame
            df = pd.DataFrame(
                ohlcv,
                columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']
            )
            
            # Convertir timestamp
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)

            # Valider donn√©es
            df = self._validate_data(df)
            
            # Mettre en cache
            if self.cache_enabled:
                self.cache[cache_key] = df.copy()
                self.cache_timestamps[cache_key] = time.time()
            
            self.logger.info(
                f"‚úÖ {len(df)} bougies charg√©es pour {symbol} {timeframe}"
            )
            
            return df
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur chargement donn√©es: {e}")
            return pd.DataFrame()
    
    def load_multi_timeframe_data(
        self,
        symbol: Optional[str] = None,
        timeframes: Optional[List[str]] = None,
        limit: int = 1000
    ) -> Dict[str, pd.DataFrame]:
        """
        Charge les donn√©es pour plusieurs timeframes
        
        Args:
            symbol: Paire de trading
            timeframes: Liste des timeframes
            limit: Nombre de bougies par TF
        
        Returns:
            Dict {timeframe: DataFrame}
        """
        
        symbol = symbol or self.symbol
        timeframes = timeframes or [self.trend_tf, self.signal_tf, self.micro_tf]
        
        self.logger.info(
            f"üì• Chargement multi-timeframe: {symbol} {timeframes}"
        )
        
        data = {}
        for tf in timeframes:
            df = self.load_historical_data(symbol, tf, limit)
            if not df.empty:
                data[tf] = df
        
        return data
    
    def update_data(
        self,
        existing_df: pd.DataFrame,
        symbol: Optional[str] = None,
        timeframe: str = '1h',
        limit: int = 10
    ) -> pd.DataFrame:
        """
        Met √† jour un DataFrame existant avec nouvelles bougies
        
        Args:
            existing_df: DataFrame existant
            symbol: Paire de trading
            timeframe: Timeframe
            limit: Nombre de nouvelles bougies √† charger
        
        Returns:
            DataFrame mis √† jour
        """
        
        symbol = symbol or self.symbol
        
        try:
            # Charger nouvelles donn√©es
            new_ohlcv = self.client.fetch_ohlcv(
                timeframe=timeframe,
                limit=limit
            )
            
            if new_ohlcv is None or len(new_ohlcv) == 0:
                return existing_df
            
            # Convertir en DataFrame
            new_df = pd.DataFrame(
                new_ohlcv,
                columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']
            )
            new_df['timestamp'] = pd.to_datetime(new_df['timestamp'], unit='ms')
            new_df.set_index('timestamp', inplace=True)
            
            # Fusionner avec donn√©es existantes
            combined = pd.concat([existing_df, new_df])
            
            # Supprimer duplicatas (garder les derniers)
            combined = combined[~combined.index.duplicated(keep='last')]
            
            # Trier par timestamp
            combined = combined.sort_index()
            
            return combined
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur mise √† jour donn√©es: {e}")
            return existing_df
    
    def get_latest_candle(
        self,
        symbol: Optional[str] = None,
        timeframe: str = '1m'
    ) -> Optional[Dict]:
        """
        R√©cup√®re la derni√®re bougie
        
        Args:
            symbol: Paire de trading
            timeframe: Timeframe
        
        Returns:
            Dict avec OHLCV ou None
        """
        
        symbol = symbol or self.symbol
        
        try:
            ohlcv = self.client.fetch_ohlcv(timeframe, limit=1)
            
            if ohlcv is None or len(ohlcv) == 0:
                return None
            
            candle = ohlcv[-1]
            return {
                'timestamp': pd.to_datetime(candle[0], unit='ms'),
                'open': candle[1],
                'high': candle[2],
                'low': candle[3],
                'close': candle[4],
                'volume': candle[5]
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur r√©cup√©ration derni√®re bougie: {e}")
            return None
    
    def resample_data(
        self,
        df: pd.DataFrame,
        target_timeframe: str
    ) -> pd.DataFrame:
        """
        Resample les donn√©es vers un autre timeframe
        
        Args:
            df: DataFrame source
            target_timeframe: Timeframe cible (ex: '1h', '4h')
        
        Returns:
            DataFrame resample
        """
        
        try:
            # Mapping timeframes pandas
            tf_map = {
                '1m': '1T',
                '5m': '5T',
                '15m': '15T',
                '1h': '1H',
                '4h': '4H',
                '1d': '1D'
            }
            
            pandas_tf = tf_map.get(target_timeframe)
            if not pandas_tf:
                self.logger.warning(f"‚ö†Ô∏è Timeframe non support√©: {target_timeframe}")
                return df
            
            # Resample
            resampled = df.resample(pandas_tf).agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            })
            
            # Supprimer NaN
            resampled = resampled.dropna()
            
            self.logger.debug(
                f"‚úÖ Donn√©es resample vers {target_timeframe}: {len(resampled)} bougies"
            )
            
            return resampled
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur resampling: {e}")
            return df
    
    def _validate_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Valide et nettoie les donn√©es
        
        Args:
            df: DataFrame √† valider
        
        Returns:
            DataFrame nettoy√©
        """
        
        # Supprimer NaN
        df = df.dropna()
        
        # V√©rifier valeurs n√©gatives
        if (df[['open', 'high', 'low', 'close', 'volume']] < 0).any().any():
            self.logger.warning("‚ö†Ô∏è Valeurs n√©gatives d√©tect√©es, suppression...")
            df = df[(df[['open', 'high', 'low', 'close', 'volume']] >= 0).all(axis=1)]
        
        # V√©rifier coh√©rence OHLC
        invalid_rows = (
            (df['high'] < df['low']) |
            (df['high'] < df['open']) |
            (df['high'] < df['close']) |
            (df['low'] > df['open']) |
            (df['low'] > df['close'])
        )
        
        if invalid_rows.any():
            num_invalid = invalid_rows.sum()
            self.logger.warning(
                f"‚ö†Ô∏è {num_invalid} bougies invalides supprim√©es"
            )
            df = df[~invalid_rows]
        
        # V√©rifier duplicatas
        duplicates = df.index.duplicated(keep='last')
        if duplicates.any():
            num_duplicates = duplicates.sum()
            self.logger.warning(
                f"‚ö†Ô∏è {num_duplicates} timestamps dupliqu√©s supprim√©s"
            )
            df = df[~duplicates]
        
        return df
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """V√©rifie si le cache est encore valide"""
        
        if not self.cache_enabled:
            return False
        
        if cache_key not in self.cache:
            return False
        
        # V√©rifier TTL
        cache_time = self.cache_timestamps.get(cache_key, 0)
        age = time.time() - cache_time
        
        return age < self.cache_ttl
    
    def _parse_date(self, date_str: str) -> int:
        """Convertit une date string en timestamp ms"""
        try:
            dt = datetime.strptime(date_str, '%Y-%m-%d')
            return int(dt.timestamp() * 1000)
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur parsing date {date_str}: {e}")
            return None
    
    def clear_cache(self):
        """Vide le cache"""
        self.cache.clear()
        self.cache_timestamps.clear()
        self.logger.info("üóëÔ∏è Cache vid√©")
    
    def get_cache_info(self) -> Dict:
        """Retourne des infos sur le cache"""
        return {
            'enabled': self.cache_enabled,
            'size': len(self.cache),
            'ttl_seconds': self.cache_ttl,
            'keys': list(self.cache.keys())
        }
    
    def warmup(self, symbols: Optional[List[str]] = None) -> bool:
        """
        Pr√©charge les donn√©es en cache (warmup)
        
        Args:
            symbols: Liste des symboles √† pr√©charger
        
        Returns:
            True si succ√®s
        """
        
        symbols = symbols or [self.symbol]
        timeframes = [self.trend_tf, self.signal_tf, self.micro_tf]
        
        self.logger.info(f"üî• Warmup cache: {len(symbols)} symboles √ó {len(timeframes)} TF")
        
        success = True
        for symbol in symbols:
            for tf in timeframes:
                df = self.load_historical_data(symbol, tf, self.lookback_medium)
                if df.empty:
                    success = False
                    self.logger.error(f"‚ùå √âchec warmup: {symbol} {tf}")
        
        if success:
            self.logger.info("‚úÖ Warmup termin√© avec succ√®s")
        
        return success
